---
title: "Group Project - Predicting Insurance Price"
author: "STAT 420, Summer 2019 - Bingxue An (bingxue3); Vivian Hu (vivianh2); Andong Jing (ajing2)"
date: 'August 3rd, 2019'
output:
  html_document: 
    toc: yes
  pdf_document: default
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
```

***

## Introduction

### Background
The Medical Cost Personal Datasets is a dataset provided by Brett Lantz (2015) in his book *Machine Learning with R*. The data was made available on [Kaggle](https://www.kaggle.com/) for public analysis by Miri Choi (2018). 

### Links and Citation
The dataset ("`insurance.csv`") is available on [Kaggle](https://www.kaggle.com/). It can be downloaded by going to [Medical Cost Personal Datasets](https://www.kaggle.com/mirichoi0218/insurance) page.

Citation:

- Lantz, B. (2015). Machine learning with R. Packt Publishing Ltd.
- Choi, M. (2018). Medical Cost Personal Datasets.

###Description of the Dataset Variables
There are totally 1337 observations of insurance data, and for each of the observation, the dataset includes the following variables:

- `Charges`: Individual medical costs billed by health insurance (numeric) - **response**
- `Sex`: Insurance contractor gender: (factor)
    - `female`
    - `male`
- `Region`: The beneficiary's residential area in the US: (factor)
    - `northeast`
    - `southeast`
    - `northwest`
    - `southwest`
- `Smoker`: The beneficiary's smoking status: (factor)
    - `yes`
    - `no`
- `bmi`: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 (numeric)
- `children`: Number of children covered by health insurance / Number of dependents (numeric)
- `age`: Age of primary beneficiary

Here are the first 5 observations of the dataset:
```{r}
insuranceData = read.csv("insurance.csv")
head(insuranceData, 5)
```

### Statement of Interest
Once upon a time, insurance agents were like local doctors - they need to know individuals and communities inside-out to give the right price. However, To match that level of knowledge in the age of decentralization and the internet, the insurance industry is turning to big data. All of the members in our group are very interested in dealing with the data in healthcare area and hope that we can develop a great model to predict insurance costs accurately.

### Model
In this project, a multiple linear regression model will be developed by selecting the best of them from several different models. The model will be used in making predictions about the insurance prices using rest of the variables.

###Goal
By applying data analysis technique on insurance data, our goal is to help the agents to give the right price to the customers more accurately and hope that we can develop a great model to predict insurance costs accurately.

***

## Methods

### Exploratory Data Analysis
To better develop our model, we would like to have an overall view of the dataset and a visualization of the dataset would be performed.
```{r}
summary(insuranceData)
```

```{r}
par(mfrow = c(1,3))
plot(charges ~ age, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. Age", cex = 1.5)
plot(charges ~ sex, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. sex", cex = 1.5)
plot(charges ~ bmi, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. bmi", cex = 1.5)
par(mfrow = c(1,3))
plot(charges ~ as.factor(children), data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. children", cex = 1.5)
plot(charges ~ smoker, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. smoker", cex = 1.5)
plot(charges ~ region, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. region", cex = 1.5)
```

As we can see, there's an obvious linear relationship between age and the charges, where charges increase as the `age` increases. We can also observe that there are three groups of lines visible. While `females` and `males` pay the same charges on average, the relationship with `bmi` is not that clear. The variable `smoker` would also be very useful since the subject who are smokers are charged much more than those who are not smokers. The relationship between charge and the number of `children` as well as the relationship between charge and `region` are less obvious. Most importantly, it is worth noticing that the distributions are skewed.

### Data Preprocessing
Before we start developing the model, we need to clean the data.
```{r}
# We want to remove all those rows with missing data
insuranceData = na.omit(insuranceData)
# We would like to consider sex,smoker and region as factor variable
if(is.factor(insuranceData$sex)==FALSE) 
  insuranceData$sex = as.factor(insuranceData$sex)
if(is.factor(insuranceData$smoker)==FALSE)
  insuranceData$smoker = as.factor(insuranceData$smoker)
if(is.factor(insuranceData$region)==FALSE)
  insuranceData$region = as.factor(insuranceData$region)
```


### Split Train and Test Data
In order to test how well our models work, we would like to splot the data into `train` and `test` sets, and develop the models on `train` while test our models on `test`.

```{r}
# 80% of the data will be used for training and the rest for testing
set.seed(420)
trainIndex = sample(1:nrow(insuranceData),round(nrow(insuranceData) * 0.80, 0))
trainSet = insuranceData[trainIndex,]
testSet = insuranceData[-trainIndex,]
```
  
### Helper functions
Before we start to build our model, we want to define some helper functions to make our job easier.
```{r}
calc_loocv_rmse = function(model) { 
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

aic = function(model){
  step(model, direction = "backward",trace = 0)
}

bic = function(model){
  step(model, direction = "backward", trace = 0, k = log(length(resid(model))))
}

# output results in a table
table = function(aic, bic) {
  results = data.frame(
    method = c("`AIC model`", "`BIC model`"),
    loocv  = c(get_loocv_rmse(aic), get_loocv_rmse(bic)), 
    params = c(length(coef(aic)), length(coef(bic)))
  )
  colnames(results) = c("", "LOOCV", "Number of Parameters")
  knitr::kable(results)
}
```

### Model Building

#### Additive Model
First we start with a full additive model as a baseline.
```{r}
full_additive = lm(charges~., data = trainSet)
summary(full_additive)
```

Then, we do the BP test and the shapiro test for this model. We find that the p-values for both tests are very close to zero, and thus, the constant variance assumption and the normality assumption for this model are violated.
```{r, warning=FALSE, message=FALSE}
library(lmtest)
bptest(full_additive)$p.value
shapiro.test(resid(full_additive))$p.value
```

The following  observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations).
```{r}
(num_influential = sum(cooks.distance(full_additive) > 4 / length(cooks.distance(full_additive))))
full_add_influential_table = knitr::kable(insuranceData[cooks.distance(full_additive) > 4 / length(cooks.distance(full_additive)),]) 
head(full_add_influential_table, 10)
```

There are 1337 observations and `r num_influential` of which are influential. The rate is `r num_influential/1337*100`%.
```{r}
cooksD = cooks.distance(full_additive)
full_additive_2 = lm(charges~., data = trainSet, subset = cooksD <= 4 / length(cooksD))

results = data.frame(coef(full_additive), coef(full_additive_2))
colnames(results) = c("With Influential Pts", "Without Influential Pts")
knitr::kable(results)
```

From the table above, we can see that most of the coefficients are influenced by the influential points, in some way but not significantly. However there are some coefficients, such as `sex:male` and `region:northwest` are significantly affected by these influential points.

#### Interaction Model

First we start with a full interaction model as a baseline.
```{r}
full_interaction = lm(charges~.^2, data = trainSet)
summary(full_interaction)
```

Then, we do the BP test and the shapiro test for this model. We find that the p-value for BP test is very large; much greater than 0.1. Thus, the constant variance assumption for this model is NOT violated. However, the shapiro test has a p-value very close to 0. Thus, the normality assumption for this model is violated.
```{r}
bptest(full_interaction)$p.value
shapiro.test(resid(full_interaction))$p.value
```


```{r}
(num_influential = sum(cooks.distance(full_interaction) > 4 / length(cooks.distance(full_interaction))))
```

The following observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations). There are 1337 observations and `r num_influential` of which are influential. The rate is `r num_influential/1337*100`%.

```{r}
full_inter_influential_table = knitr::kable(trainSet[cooks.distance(full_interaction) > 4 / length(cooks.distance(full_interaction)),])
head(full_inter_influential_table, 10)
```

We perform variable selection using backwards AIC. The resulting model is denoted as `interaction_aic`
```{r}
n = length(resid(full_interaction))
interaction_aic = step(full_interaction, direction = "backward", trace = 0)
```

We perform ANOVA  test for `interaction_aic` model and `full_interaction` model. We find that the p-value is `r anova(interaction_aic,full_interaction)[2,"Pr(>F)"]` > 0.1, thus we prefer the `interaction_aic` model.
```{r}
anova(interaction_aic,full_interaction)
```

#### Polynomial Model
First we start with a model containing the first and second order of every variable.
```{r}
full_polynomial = lm(charges~ . +I(age^2) +I(bmi^2) +I(children^2), data = trainSet)
summary(full_polynomial)
```

Then, we perform the BP test and the shapiro test for this model. We find that the p-values for both tests are very close to zero, and thus, the constant variance assumption and the normality assumption for this model are violated.
```{r}
bptest(full_polynomial)$p.value
shapiro.test(resid(full_polynomial))$p.value
```

```{r}
(num_influential = sum(cooks.distance(full_polynomial) > 4 / length(cooks.distance(full_polynomial))))
```

The following observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations). There are 1337 observations and `r num_influential` of which are influential. The rate is `r num_influential/1337*100`%.
```{r}
full_poly_influential_table = knitr::kable(trainSet[cooks.distance(full_polynomial) > 4 / length(cooks.distance(full_polynomial)),])
head(full_poly_influential_table, 10)
```

#### Combined Model
```{r}
#add an additional column, which will be used for combined model, explanations will be provided later
trainSet$bmi30 = ifelse(trainSet$bmi >= 30, "yes", "no")
combined_model = lm(charges ~ age + I(age^2) + children + bmi + sex + bmi30 * smoker + region, data=trainSet)
summary(combined_model)
```

Then, we perform the BP test and the shapiro test for this model. We find that the p-values for shapiro test is very close to zero, and thus, the normality assumption for this model are violated.
```{r}
bptest(combined_model)$p.value
shapiro.test(resid(combined_model))$p.value
```


***

## Result
```{r}
anova(full_additive, interaction_aic)
anova(full_polynomial, interaction_aic)
summary(interaction_aic)$"adj.r.squared"
```
Since two p-values are less than 0.01, we choose `interaction_aic` model.

***

## Discussion


```{r}
summary(full_additive)$"adj.r.squared"
summary(full_polynomial)$"adj.r.squared"
summary(interaction_aic)$"adj.r.squared"
summary(combined_model)$"adj.r.squared"
```
For the additive model, it violates both the constant variance assumption and the normality assumption. It has an adjusted $R^2$ value of `r summary(full_additive)$"adj.r.squared"`.

For the full_polynomail model, it violates both the constant variance assumption and the normality assumption. It has an adjusted $R^2$ value of `r summary(full_polynomial)$"adj.r.squared"`.

For the interactive model, it supports the constant variance assumption but violates the normality assumption. It has an adjusted $R^2$ value `r summary(interaction_aic)$"adj.r.squared"`.

We can see that the interactive model has the greatest $R^2$ value.



```{r}
RMSE = function( model, data = NULL){
  if (is.null(data)){
    return (sqrt(mean((model$residuals)^2 )))
  }
  predict_val = predict(model, newdata = data)
  return(sqrt(mean((data$charges - predict_val) ^ 2)))
}
RMSE(full_additive, insuranceData)
RMSE(full_polynomial, insuranceData)
RMSE(interaction_aic, insuranceData)
insuranceData$bmi30 = ifelse(insuranceData$bmi >= 30, "yes", "no")
RMSE(combined_model, insuranceData)

```
For the additive model, it has a RMSE value of `r RMSE(full_additive, insuranceData)`.

For the polynomail model, it has a RMSE value of `r RMSE(full_polynomial, insuranceData)`.

For the interactive model, it has a RMSE value of `r RMSE(interaction_aic, insuranceData)`.

We can see that the interactive model has the smallest RMSE value.