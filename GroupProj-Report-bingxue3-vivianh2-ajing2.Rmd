---
title: "Group Project - Predicting Insurance Price"
author: "STAT 420, Summer 2019 - Bingxue An (bingxue3); Vivian Hu (vivianh2); Andong Jing (ajing2)"
date: 'August 3rd, 2019'
output:
  html_document: 
    toc: yes
  pdf_document: default
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
```

***

## Introduction

### Background
The Medical Cost Personal Datasets is a dataset provided by Brett Lantz (2015) in his book *Machine Learning with R*. The data was made available on [Kaggle](https://www.kaggle.com/) for public analysis by Miri Choi (2018). 

### Links and Citation
The dataset ("`insurance.csv`") is available on [Kaggle](https://www.kaggle.com/). It can be downloaded by going to [Medical Cost Personal Datasets](https://www.kaggle.com/mirichoi0218/insurance) page.

Citation:

- Lantz, B. (2015). Machine learning with R. Packt Publishing Ltd.
- Choi, M. (2018). Medical Cost Personal Datasets.

###Description of the Dataset Variables
There are totally 1337 observations of insurance data, and for each of the observation, the dataset includes the following variables:

- `Charges`: Individual medical costs billed by health insurance (numeric) - **response**
- `Sex`: Insurance contractor gender: (factor)
    - `female`
    - `male`
- `Region`: The beneficiary's residential area in the US: (factor)
    - `northeast`
    - `southeast`
    - `northwest`
    - `southwest`
- `Smoker`: The beneficiary's smoking status: (factor)
    - `yes`
    - `no`
- `bmi`: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 (numeric)
- `children`: Number of children covered by health insurance / Number of dependents (numeric)
- `age`: Age of primary beneficiary

Here are the first 5 observations of the dataset:
```{r}
insuranceData = read.csv("insurance.csv")
head(insuranceData, 5)
```

### Statement of Interest
Once upon a time, insurance agents were like local doctors - they need to know individuals and communities inside-out to give the right price. However, To match that level of knowledge in the age of decentralization and the internet, the insurance industry is turning to big data. All of the members in our group are very interested in dealing with the data in healthcare area and hope that we can develop a great model to predict insurance costs accurately.

### Model
In this project, a multiple linear regression model will be developed by selecting the best of them from several different models. The model will be used in making predictions about the insurance prices using rest of the variables.

###Goal
By applying data analysis technique on insurance data, our goal is to help the agents to give the right price to the customers more accurately and hope that we can develop a great model to predict insurance costs accurately.

***

## Methods

### Exploratory Data Analysis
To better develop our model, we would like to have an overall view of the dataset and a visualization of the dataset would be performed.
```{r}
summary(insuranceData)
```

```{r}
par(mfrow = c(1,3))
plot(charges ~ age, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. Age", cex = 1.5)
plot(charges ~ sex, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. sex", cex = 1.5)
plot(charges ~ bmi, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. bmi", cex = 1.5)
par(mfrow = c(1,3))
plot(charges ~ as.factor(children), data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. children", cex = 1.5)
plot(charges ~ smoker, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. smoker", cex = 1.5)
plot(charges ~ region, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. region", cex = 1.5)
```

As we can see, there's an obvious linear relationship between age and the charges, where charges increase as the `age` increases. We can also observe that there are three groups of lines visible. While `females` and `males` pay the same charges on average, the relationship with `bmi` is not that clear. The variable `smoker` would also be very useful since the subject who are smokers are charged much more than those who are not smokers. The relationship between charge and the number of `children` as well as the relationship between charge and `region` are less obvious. Most importantly, it is worth noticing that the distributions are skewed.

### Data Preprocessing
Before we start developing the model, we need to clean the data.
```{r}
# We want to remove all those rows with missing data
insuranceData = na.omit(insuranceData)
# We would like to consider sex,smoker and region as factor variable
if(is.factor(insuranceData$sex)==FALSE) 
  insuranceData$sex = as.factor(insuranceData$sex)
if(is.factor(insuranceData$smoker)==FALSE)
  insuranceData$smoker = as.factor(insuranceData$smoker)
if(is.factor(insuranceData$region)==FALSE)
  insuranceData$region = as.factor(insuranceData$region)
```


### Split Train and Test Data
In order to test how well our models work, we would like to splot the data into `train` and `test` sets, and develop the models on `train` while test our models on `test`.

```{r}
# 80% of the data will be used for training and the rest for testing
set.seed(420)
trainIndex = sample(1:nrow(insuranceData),round(nrow(insuranceData) * 0.80, 0))
trainSet = insuranceData[trainIndex,]
testSet = insuranceData[-trainIndex,]
```
  
### Helper functions
Before we start to build our model, we want to define some helper functions to make our job easier.
```{r}
calc_loocv_rmse = function(model) { 
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

aic = function(model){
  step(model, direction = "backward",trace = 0)
}

bic = function(model){
  step(model, direction = "backward", trace = 0, k = log(length(resid(model))))
}

# output results in a table
table = function(aic, bic) {
  results = data.frame(
    method = c("`AIC model`", "`BIC model`"),
    loocv  = c(get_loocv_rmse(aic), get_loocv_rmse(bic)), 
    params = c(length(coef(aic)), length(coef(bic)))
  )
  colnames(results) = c("", "LOOCV", "Number of Parameters")
  knitr::kable(results)
}

#This function calculates the RMSE of a dataset.
RMSE = function( model, data = NULL){
  if (is.null(data)){
    return (sqrt(mean((model$residuals)^2 )))
  }
  predict_val = predict(model, newdata = data)
  return(sqrt(mean((data$charges - predict_val) ^ 2)))
}
```

### Model Building

#### Additive Model
First we start with a full additive model as a baseline.
```{r}
full_additive = lm(charges~., data = trainSet)
summary(full_additive)
```

Then, we do the BP test and the shapiro test for this model. We find that the p-values for both tests are very close to zero, and thus, the constant variance assumption and the normality assumption for this model are violated.
```{r, warning=FALSE, message=FALSE}
library(lmtest)
bptest(full_additive)$p.value
shapiro.test(resid(full_additive))$p.value
```

The following  observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations).
```{r}
(num_influential = sum(cooks.distance(full_additive) > 4 / length(cooks.distance(full_additive))))
full_add_influential_table = knitr::kable(insuranceData[cooks.distance(full_additive) > 4 / length(cooks.distance(full_additive)),]) 
head(full_add_influential_table, 10)
```

There are 1337 observations and `r num_influential` of which are influential. The rate is `r num_influential/1337*100`%.
```{r}
cooksD = cooks.distance(full_additive)
full_additive_2 = lm(charges~., data = trainSet, subset = cooksD <= 4 / length(cooksD))

results = data.frame(coef(full_additive), coef(full_additive_2))
colnames(results) = c("With Influential Pts", "Without Influential Pts")
knitr::kable(results)
```

From the table above, we can see that most of the coefficients are influenced by the influential points, in some way but not significantly. However there are some coefficients, such as `sex:male` and `region:northwest` are significantly affected by these influential points.

#### Interaction Model

First we start with a full interaction model as a baseline.
```{r}
full_interaction = lm(charges~.^2, data = trainSet)
summary(full_interaction)
```

Then, we do the BP test and the shapiro test for this model. We find that the p-value for BP test is very large; much greater than 0.1. Thus, the constant variance assumption for this model is NOT violated. However, the shapiro test has a p-value very close to 0. Thus, the normality assumption for this model is violated.
```{r}
bptest(full_interaction)$p.value
shapiro.test(resid(full_interaction))$p.value
```


```{r}
(num_influential = sum(cooks.distance(full_interaction) > 4 / length(cooks.distance(full_interaction))))
```

The following observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations). There are 1337 observations and `r num_influential` of which are influential. The rate is `r num_influential/1337*100`%.

```{r}
full_inter_influential_table = knitr::kable(trainSet[cooks.distance(full_interaction) > 4 / length(cooks.distance(full_interaction)),])
head(full_inter_influential_table, 10)
```

We perform variable selection using backwards AIC. The resulting model is denoted as `interaction_aic`
```{r}
n = length(resid(full_interaction))
interaction_aic = step(full_interaction, direction = "backward", trace = 0)
```

We perform ANOVA  test for `interaction_aic` model and `full_interaction` model. We find that the p-value is `r anova(interaction_aic,full_interaction)[2,"Pr(>F)"]` > 0.1, thus we prefer the `interaction_aic` model.
```{r}
anova(interaction_aic,full_interaction)
```

#### Polynomial Model
First we start with a model containing the first and second order of every variable.
```{r}
full_polynomial = lm(charges~ . +I(age^2) +I(bmi^2) +I(children^2), data = trainSet)
summary(full_polynomial)
```

Then, we perform the BP test and the shapiro test for this model. We find that the p-values for both tests are very close to zero, and thus, the constant variance assumption and the normality assumption for this model are violated.
```{r}
bptest(full_polynomial)$p.value
shapiro.test(resid(full_polynomial))$p.value
```

```{r}
(num_influential = sum(cooks.distance(full_polynomial) > 4 / length(cooks.distance(full_polynomial))))
```

The following observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations). There are 1337 observations and `r num_influential` of which are influential. The rate is `r num_influential/1337*100`%.
```{r}
full_poly_influential_table = knitr::kable(trainSet[cooks.distance(full_polynomial) > 4 / length(cooks.distance(full_polynomial)),])
head(full_poly_influential_table, 10)
```

#### Combined Model
```{r}
#add an additional column, which will be used for combined model, explanations will be provided later
trainSet$bmi30 = ifelse(trainSet$bmi >= 30, "yes", "no")
combined_model = lm(charges ~ age + I(age^2) + children + bmi + sex + bmi30:smoker + region, data=trainSet)
summary(combined_model)
```

Then, we perform the BP test and the shapiro test for this model. We find that the p-values for shapiro test is very close to zero, and thus, the normality assumption for this model are violated.
```{r}
bptest(combined_model)$p.value
shapiro.test(resid(combined_model))$p.value
```


***

## Result
```{r}
anova(full_additive, interaction_aic)
anova(full_polynomial, interaction_aic)
```

```{r}
RMSE_trn = c(RMSE(full_additive), RMSE(interaction_aic), RMSE(full_polynomial), RMSE(combined_model))
testSet_combined = testSet
testSet_combined$bmi30 = ifelse(testSet_combined$bmi >= 30, "yes", "no")
RMSE_test = c(RMSE(full_additive, testSet), RMSE(interaction_aic, testSet), RMSE(full_polynomial, testSet), RMSE(combined_model, testSet_combined))
knitr::kable(data.frame(variable = c("additive", "interactive", "polynomial", "combined"), RMSE_trn, RMSE_test))
```

```{r}
knitr::kable(data.frame(model = c("additive", "interactive", "polynomial", "combined"), "adjusted R squared" = c(summary(full_additive)$"adj.r.squared", summary(interaction_aic)$"adj.r.squared", summary(full_polynomial)$"adj.r.squared", summary(combined_model)$"adj.r.squared")))
```

***

## Discussion

- From the two ANOVA performed in **Result** section, two p-values are less than 0.01, meaning that we reject the null hypothesis. Thus, we can conclude that the interaction between variables are significant.

- From the table of adjusted $R^2$, we find that the combined model has the greatest $R^2$ value and thus this model fits the data best.

- We find that only the interactive model satisfies the constant variance assumption from the B-P test, and all three models violates the normality assumption.

- From the table of RMSE, we find that the combined model has the smallest RMSE, for both training and testing data.

For the first full_additivee model, we only utilized those given variables included in the dataset and actually got a relatively good r-squared of 0.743, which indicates that 74.3% of the variation of charges could be explained by the variables we have included. We could also observe most of the variables we included are statistically significant predictors for medical charges.

For the last combined model, notice that we actually created a new variable called bmi30, which separate bmi into two categories by whether its value is above 30 or not. The reason to split by 30 is because 30 is the threshold for obesity, and we obesity is an indicator of a person's health condition. What's more, we also added a I(age^2) variable, because as we saw in the *Charge vs. Age* plot, the realtionship between age and charges are not only limited to linear, so we want to include I(age^2) in order to introduce some non-linearity in out model. The result is obviously better comparing to all other previous models. We get a r-squared of 0.863, which indicates that 86.3% of the variation of charges are explained by thiis combined model. What's more, this model's adjusted r-squared and RMSE are the lowest among the all. Therefore, we believe this is the best model.
