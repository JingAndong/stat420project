---
title: "Group Project - Predicting Insurance Price"
author: "STAT 420, Summer 2019 - Bingxue An (bingxue3); Vivian Hu (vivianh2); Andong Jing (ajing2)"
date: 'July-17th 2019'
output:
  html_document: 
    toc: yes
  pdf_document: default
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
```
  
## Introduction

### Background
The Medical Cost Personal Datasets is a dataset provided by Brett Lantz (2015) in his book *Machine Learning with R*. The data was made available on [Kaggle](https://www.kaggle.com/) for public analysis by Miri Choi (2018). In this project, a multiple linear regression model will be developed by selecting the best of them from several different models. The model will be used in making predictions about the insurance prices using rest of the variables.
  
###Description of the Dataset
There are totally 1337 observations of insurance data, and for each of the observation, the dataset includes the following variables:

- `Charges`: Individual medical costs billed by health insurance (numeric) - **response**
- `Sex`: Insurance contractor gender: (factor)
    - `female`
    - `male`
- `Region`: The beneficiary's residential area in the US: (factor)
    - `northeast`
    - `southeast`
    - `northwest`
    - `southwest`
- `Smoker`: The beneficiary's smoking status: (factor)
    - `yes`
    - `no`
- `bmi`: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 (numeric)
- `children`: Number of children covered by health insurance / Number of dependents (numeric)
- `age`: Age of primary beneficiary

Here are the first 5 observations of the dataset:
```{r}
insuranceData = read.csv("insurance.csv")
head(insuranceData, 5)
```


### Links and Citation:
The dataset ("`insurance.csv`") is available on [Kaggle](https://www.kaggle.com/). It can be downloaded by going to [Medical Cost Personal Datasets](https://www.kaggle.com/mirichoi0218/insurance) page.

Citation:
Lantz, B. (2015). Machine learning with R. Packt Publishing Ltd.
Choi, M. (2018). Medical Cost Personal Datasets.

## Methods

### Data Visualization:
To better develop our model, we would like to have a overall view of the dataset and a visualization of the dataset would be performed.
```{r}
insuranceData = read.csv("insurance.csv")
par(mfrow = c(1,3))
plot(charges ~ age, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. Age", cex = 1.5)
plot(charges ~ sex, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. sex", cex = 1.5)
plot(charges ~ bmi, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. bmi", cex = 1.5)
par(mfrow = c(1,3))
plot(charges ~ children, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. children", cex = 1.5)
plot(charges ~ smoker, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. smoker", cex = 1.5)
plot(charges ~ region, data = insuranceData, pch = 20, col = "dodgerblue",main = "Charges vs. region", cex = 1.5)
```
As we can see, there's a very obvious linear relationship between age and the charges. The variable "smoker" would also be very useful since the subject who are smokers are charged much more than those who are not. The relationship between charge and the rest of the variables are not obvious. 
  
### Data Preprocessing
Before we start developing the model, we need to clean the data.
```{r}
insuranceData = read.csv("insurance.csv")
# We want to remove all those rows with missing data
insuranceData = na.omit(insuranceData)
# We would like to consider sex,smoker and region as factor variable
if(is.factor(insuranceData$sex)==FALSE)
  insuranceData$sex = as.factor(insuranceData$sex)
if(is.factor(insuranceData$smoker)==FALSE)
  insuranceData$smoker = as.factor(insuranceData$smoker)
if(is.factor(insuranceData$region)==FALSE)
  insuranceData$region = as.factor(insuranceData$region)
```
  
In order to test how well our models work, we would like to splot the data into 'train' and 'test' sets, and develop the models on 'train' while test our models on 'test'.

```{r}
# 80% of the data will be used for training and the rest for testing
trainIndex = sample(1:nrow(insuranceData),round(nrow(insuranceData) * 0.80, 0))
trainSet = insuranceData[trainIndex,]
testSet = insuranceData[-trainIndex,]
```
  
### Helper functions
Before we start to build our model, we want to define some helper functions to make our job easier.
```{r}
calc_loocv_rmse = function(model) { 
  sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
}

aic = function(model){
  step(model, direction = "backward",trace = 0)
}

bic = function(model){
  step(model, direction = "backward", trace = 0, k = log(length(resid(model))))
}

# output results in a table
table = function(aic, bic) {
  results = data.frame(
    method = c("`AIC model`", "`BIC model`"),
    loocv  = c(get_loocv_rmse(aic), get_loocv_rmse(bic)), 
    params = c(length(coef(aic)), length(coef(bic)))
  )
  colnames(results) = c("", "LOOCV", "Number of Parameters")
  knitr::kable(results)
}
```

### Develop of the model


#### Additive Model
First we start with a full additive model as a baseline.
```{r}
full_additive = lm(charges~., data = insuranceData)
```

Then, we do the BP test and the shapiro test for this model. We find that the p-values for both tests are very close to zero, and thus, the constant variance assumption and the normality assumption for this model are violated.
```{r}
library(lmtest)
bptest(full_additive)$p.value
shapiro.test(resid(full_additive))$p.value
```


The following  observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations).
```{r}
sum(cooks.distance(full_additive) > 4 / length(cooks.distance(full_additive)))
full_add_influential_table = knitr::kable(insuranceData[cooks.distance(full_additive) > 4 / length(cooks.distance(full_additive)),]) 
head(full_add_influential_table, 10)
```

There are 1337 observations and 87 of which are influential. The rate is `r 87/1337*100`%.
```{r}
cooksD = cooks.distance(full_additive)
full_additive_2 = lm(charges~., data = insuranceData, subset = cooksD <= 4 / length(cooksD))

results = data.frame(coef(full_additive), coef(full_additive_2))
colnames(results) = c("With Influential Pts", "Without Influential Pts")
knitr::kable(results)
```

From the table above, we can see that most of the coefficients are influenced by the influential points, in some way but not significantly. However there are some coefficients, such as `sex:male` and `region:northwest` are significantly affected by these influential points.

#### Interaction Model

First we start with a full interaction model as a baseline.
```{r}
full_interaction = lm(charges~.^2, data = insuranceData)
```

Then, we do the BP test and the shapiro test for this model. We find that the p-value for BP test is very large; much greater than 0.1. Thus, the constant variance assumption for this model is NOT violated. However, the shapiro test has a p-value very close to 0. Thus, the normality assumption for this model is violated.
```{r}
library(lmtest)
bptest(full_interaction)$p.value
shapiro.test(resid(full_interaction))$p.value
```


The following observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations). There are 1337 observations and 110 of which are influential. The rate is `r 93/1337*100`%.
```{r}
sum(cooks.distance(full_interaction) > 4 / length(cooks.distance(full_interaction)))
full_inter_influential_table = knitr::kable(insuranceData[cooks.distance(full_interaction) > 4 / length(cooks.distance(full_interaction)),])
head(full_inter_influential_table, 10)
```

we perform variable selection using backwards AIC. The resulting model is denoted as `interaction_aic`
```{r}
n = length(resid(full_interaction))
interaction_aic = step(full_interaction, direction = "backward", trace = 0)
```

We perform ANOVA  test for `interaction_aic` model and `full_interaction` model. We find that the p-value is `r anova(interaction_aic,full_interaction)[2,"Pr(>F)"]` > 0.1, thus we prefer the `interaction_aic` model.
```{r}
anova(interaction_aic,full_interaction)
```

#### Polynomial Model
First we start with a model containing the first and second order of every variable.
```{r}
full_polynomail = lm(charges~ . +I(age^2) +I(bmi^2) +I(children^2), data = insuranceData)
```

Then, we perform the BP test and the shapiro test for this model. We find that the p-values for both tests are very close to zero, and thus, the constant variance assumption and the normality assumption for this model are violated.
```{r}
library(lmtest)
bptest(full_polynomail)$p.value
shapiro.test(resid(full_polynomail))$p.value
```

The following observations are those we believe influential (have Cook’s Distance is greater than 4/n, where n is the total number of observations). There are 1337 observations and 81 of which are influential. The rate is `r 93/1337*100`%.
```{r}
sum(cooks.distance(full_polynomail) > 4 / length(cooks.distance(full_polynomail)))
full_poly_influential_table = knitr::kable(insuranceData[cooks.distance(full_polynomail) > 4 / length(cooks.distance(full_polynomail)),])
head(full_poly_influential_table, 10)
```


## Result
```{r}
anova(full_additive, interaction_aic)
anova(full_polynomail, interaction_aic)
summary(interaction_aic)$"adj.r.squared"
```
Since two p-values are less than 0.01, we choose `interaction_aic` model.

## Discussion


```{r}
summary(full_additive)$"adj.r.squared"
summary(full_polynomail)$"adj.r.squared"
summary(interaction_aic)$"adj.r.squared"
```
For the additive model, it violates both the constant variance assumption and the normality assumption. It has an adjusted $R^2$ value of `r summary(full_additive)$"adj.r.squared"`.

For the full_polynomail model, it violates both the constant variance assumption and the normality assumption. It has an adjusted $R^2$ value of `r summary(full_polynomail)$"adj.r.squared"`.

For the interactive model, it supports the constant variance assumption but violates the normality assumption. It has an adjusted $R^2$ value `r summary(interaction_aic)$"adj.r.squared"`.

We can see that the interactive model has the greatest $R^2$ value.



```{r}
RMSE = function( model, data = NULL){
  if (is.null(data)){
    return (sqrt(mean((model$residuals)^2 )))
  }
  predict_val = predict(model, newdata = data)
  return(sqrt(mean((data$charges - predict_val) ^ 2)))
}
RMSE(full_additive, insuranceData)
RMSE(full_polynomail, insuranceData)
RMSE(interaction_aic, insuranceData)
```
For the additive model, it has a RMSE value of `r RMSE(full_additive, insuranceData)`.

For the polynomail model, it has a RMSE value of `r RMSE(full_polynomail, insuranceData)`.

For the interactive model, it has a RMSE value of `r RMSE(interaction_aic, insuranceData)`.

We can see that the interactive model has the smallest RMSE value.